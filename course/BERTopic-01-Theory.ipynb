{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BERTopic and Other LLM-Based Topic Models"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LDA, like most classical topic models, understands words as distinct features of documents, where the appearances of words in documents are independent of each other, except for the topic-word distribution which the model learns.\n",
    "This assumption is not true in real life, where words are related to each other in a semantic way. For example, the words \"dog\" and \"cat\" are more similar than \"dog\" and \"apple\".\n",
    "\n",
    "In this way, Embeddings-Based Topic Models (EBTM) can be understood as introducing a prior on the topic-word distribution, which is based on the pretrained semantic similarity between words. This prior is expressed as an additional layer of abstraction, where the topic-word distribution is a function of the word embeddings, instead of the word-counts themselves.\n",
    "\n",
    "In contrast to LDA, most EBTM models, hence, are not generative. Instead, they follow a bottom-up approach. First, documents are embedded in the new, semantic embedding space, and then, topics are extracted from the documents in this new space.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BERTopic"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BERTopic is a plug-and-play topic modeling technique that leverages BERT embeddings and c-TF-IDF to create dense clusters allowing for easily interpretable topics whilst keeping important words in the topic descriptions.\n",
    "It works by composing six submodules, which can be subsumed in three overarching steps:\n",
    "\n",
    "**Topic Generation**\n",
    "* *Document Embedding* is the process of encoding documents into vectors. By default, BERTopic uses the [sentence-transformers](https://www.sbert.net/) library to embed documents in a semantic embedding space.\n",
    "* *Dimensionality Reduction* refers to \n",
    "* Clustering\n",
    "\n",
    "**Topic Inspection**\n",
    "* Vectorization\n",
    "* Description Creation\n",
    "\n",
    "**Fine-tuning**\n",
    "* Fine-tuning"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
